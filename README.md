##基于朴素贝叶斯分类器的推特数据研究

这个是电子科技大学通信学院的一个给学生练手的小项目。构建一个朴素贝叶斯算法的分类器，然后使用从网络上爬取的一定时间段内的推特数据进行训练，使其能够将之后的测试数据进行聚类，分为‘新闻’和‘非新闻’两类。

使用了 监督学习

第一步：
首先对两个输入的训练样本进行清洗（Data_Processing.py），将每条推特的的text部分提取到list里，然后按照空格对list里的每一项item进行划分，得到每一个分词。之后再统一大小写，去除text后的网址，@信息，#（话题）后的词语要作为普通的分词加入text，接下来去掉分词组中的语义无关词（比如字母长度小于2的词，are and will the this that等）

第二步：
将清洗好的数据进行统计，得到每一个词在总词库中出现的频率，并将其频率作为该词出现的概率。再将所有词按照出现概率大小排列成dict输出

第三步：
使用统计好的结果对贝叶斯模型进行计算。即将每个在样本中出现过的词作为样本的一个属性，计算其条件概率。这一个过程即称为训练

第四步：
将测试样本清洗后输入模型，对测试样本里的每一条推特，在训练器中查找其对应的条件概率，若该属性缺失则将概率记为1，最后将算出来的所有条件概率之积进行比较。值得注意的是，因为所有条件概率之积算出来极小（大约为10e-324），计算机无法进行除法来比较大小，所以每计算一个条件概率就进行一次聚类，比较该条推特是新闻的概率和是非新闻的概率哪个大，并进行记录和统计。